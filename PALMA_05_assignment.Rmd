---
title: 'Assignment #5'
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
# SEE modeldata package for new datasets
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(ranger)            # for random forest - will need for shiny app
library(lubridate)         # for date manipulation
library(themis)            # for up and downsampling
library(DALEX)             # for model interpretation  
library(DALEXtra)          # for extension of DALEX
theme_set(theme_minimal()) # Lisa's favorite theme
```

```{r data}
data("lending_club")
# Data dictionary (as close as I could find): https://www.kaggle.com/wordsforthewise/lending-club/discussion/170691
```


## Put it on GitHub! -- DONE        


Github Repo Link: https://github.com/apalma127/assignment-5


## Interpretable ML methods -- ____

We will once again use the lending club data that we used in the 3rd assignment. We will focus on the random forest model, which I recreate below. (Note we use this model even though the true negative rate of the training set is quite bad.)

```{r}
set.seed(494) # for reproducibility

#split data
lending_split <- initial_split(lending_club,
                               prop = .75,
                               strata = Class)

lending_training <- training(lending_split)
lending_test <- testing(lending_split)


#create recipe - including up and downsampling for model fitting
set.seed(456)
rf_recipe <- 
  recipe(Class ~ .,
         data = lending_training) %>% 
  step_upsample(Class, over_ratio = .5) %>% 
  step_downsample(Class, under_ratio = 1) %>% 
  step_mutate_at(all_numeric(), 
                 fn = ~as.numeric(.))

# create model
rf_model <- 
  rand_forest(mtry = tune(), 
              min_n = tune(), 
              trees = 100) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

# create workflow
rf_workflow <-
  workflow() %>% 
  add_recipe(rf_recipe) %>% 
  add_model(rf_model)

  grid_regular(finalize(mtry(),
                        lending_training %>%
                          select(-Class)),
               min_n(),
               levels = 3)

# create penalty grid
  rf_penalty_grid <- 
grid_regular(finalize(mtry(),
                        lending_training %>%
                          select(-Class)),
               min_n(),
               levels = 3)


# create cv samples
set.seed(494) #for reproducible 5-fold
lending_cv <- vfold_cv(lending_training,
                       v = 5)

# tune model
rf_tune <- 
  rf_workflow %>% 
  tune_grid(
    resamples = lending_cv,
    grid = rf_penalty_grid
  )

# find model with best accuracy
best_accuracy <-
  rf_tune %>% 
  select_best(metric = "accuracy")

# finalize model
rf_final <- rf_workflow %>% 
  finalize_workflow(best_accuracy) %>% 
  fit(data = lending_training)
```

1. Use functions from the `DALEX` and `DALEXtra` libraries to create a histogram and boxplot of the residuals from the training data. 

```{r}
lending_training <- lending_training %>%
  mutate(Class = ifelse(Class == "good", 1, 0))
  
```



```{r}
rf_explain <- 
  explain_tidymodels(
    model = rf_final,
    data = lending_training %>% select(-Class), 
    y = lending_training %>%  pull(Class),
    label = "rf", 
    type = "classification"
  )

```


```{r}
rf_mod_perf <-  model_performance(rf_explain, na.omit())

rf_mod_perf
```




```{r}
hist_plot <- 
  plot(rf_mod_perf,
       geom = "histogram")


box_plot <-
  plot(rf_mod_perf,
       geom = "boxplot")

```


```{r}
hist_plot
```

```{r}
box_plot
```



**How do they look? Any interesting behavior?**

They are not centered around 0 as you would want a good model to do. They appear to skew right heavily well into the positives indicating a continuous underprediction.  This is very significant as it shows a pattern of underpredictions which shouldn't be a constant pattern if it is a good model. 


2. Use `DALEX` functions to create a variable importance plot from this model. 

```{r}
set.seed(2) 
rf_var_imp <- 
  model_parts(
    rf_explain
    )

plot(rf_var_imp, show_boxplots = TRUE)
```



**What are the most important variables?**

The most importannt variables used to help correctly predict if a loan was paid back was **interest rate**, **sub_grade**, **open_il_24m**, and **annual income**.  These are not surprising at all because most of them relate exactly back to affecting one's ability to repay ... ie if an interest rate is incredibly high it makes the pay back extremely less likely, if one has a very low income it makes payback very difficult....


3. Write a function called `cp_profile` to make a CP profile. 

The function will take an explainer, 
a new observation, 
and a variable name as its arguments and 

create a CP profile for a quantitative predictor variable. 


You will need to use the `predict_profile()` function inside the function you create - 
put the variable name there so the plotting part is easier.


```{r}
obs2 <- lending_training %>% 
  slice(2)
obs2
```
```{r}
#is.integer(lending_training$annual_inc)
is.integer(lending_training$int_rate)

```





```{r}
cp_profile <- predict_profile(explainer = rf_explain, 
                          new_observation = obs2,
                          variables = c("annual_inc", "int_rate"))


cp_profile
```

You'll also want to use `.data[[]]` rather than `aes()` and quote the variables. Use the `cp_profile()` function to create one CP profile of your choosing. Be sure to choose a variable that is numeric, not integer. There seem to be issues with those that I'm looking into.

```{r}
cp_profile %>% 
  filter(`_vname_` %in% c("annual_inc")) %>% 
  ggplot(aes(x = annual_inc,
             y = `_yhat_`)) +
  geom_line() 
```

**With y_hat being our predicted class outcome (with 1 = good pay back on time and 0 = bad not paid back on time) it appears to show us: as income increases, while it doesn;t appear to be a major difference, it is slightly more likely the person is not on time w repayment.  Yet, it appears it is much more constant w the trend line for higher income whereas lower icnome is much more chaotic in predicted payback.** 



```{r}
cp_profile %>% 
  filter(`_vname_` %in% c("int_rate")) %>% 
  ggplot(aes(x = int_rate,
             y = `_yhat_`)) +
  geom_line() 
```

**With y_hat being our predicted class outcome (with 1 = good pay back on time and 0 = bad not paid back on time) it appears to show us a very obvious trend.  As expected, as the interest rate increases meaning increasingly more money is owed back than borrowed, the ability to pay on time and the predicted class value races downarward closer to bad meaning the payment will not be on time.** 



**Write a function to do this!!!!!** 




----------------------------









For an extra challenge, write a function that will work for either a quantitative or categorical variable. 

If you need help with function writing check out the [Functions](https://r4ds.had.co.nz/functions.html) chapter of R4DS by Wickham and Grolemund.

4. Use `DALEX` functions to create partial dependence plots (with the CP profiles in gray) for the 3-4 most important variables. If the important variables are categorical, you can instead make a CP profile for 3 observations in the dataset and discuss how you could go about constructing a partial dependence plot for a categorical variable (you don't have to code it, but you can if you want an extra challenge). If it ever gives you an error that says, "Error: Can't convert from `VARIABLE` <double> to `VARIABLE` <integer> due to loss of precision", then remove that variable from the list. I seem to have figured out why it's doing that, but I don't know how to fix it yet.

5. Choose 3 observations and do the following for each observation:  
  - Construct a break-down plot using the default ordering. Interpret the resulting graph. Which variables contribute most to each observation's prediction?  
  - Construct a SHAP graph and interpret it. Does it tell a similar story to the break-down plot?  
  - Construct a LIME graph (follow my code carefully). How close is each original prediction to the prediction from the local model? Interpret the result. You can also try using fewer or more variables in the local model than I used in the example.  
  
6. Describe how you would use the interpretable machine learning tools we've learned (both local and global) in future machine learning projects? How does each of them help you?

7. (WARNING: I may have to make some changes to how you save this. I will do that by Friday at the latest.) Save this final model using the `saveRDS()` function - see the [Use the model](https://advanced-ds-in-r.netlify.app/posts/2021-03-16-ml-review/#use-the-model) section of the `tidymodels` intro. We are going to use the model in the next part. You'll want to save it in the folder where you create your shiny app.

## Shiny app -- ____

(WARNING: I may make some small changes to this as well which I will also update by Friday.)

You are going to create an app that allows a user to explore how the predicted probability of a loan being paid back (or maybe just the predicted class - either "good" or "bad") changes depending on the values of the predictor variables.

Specifically, you will do the following:

* Set up a separate project and GitHub repo for this app. Make sure the saved model from the previous problem is also in that folder. The app needs to be created in a file called *exactly* app.R that is also in the project folder. 


* At the top of the file, load any libraries you use in the app.  
* Use the `readRDS()` function to load the model.  
* You may want to load some of the data to use
* Create a user interface (using the various `*Input()` functions) where someone could enter values for each variable that feeds into the model. You will want to think hard about which types of `*Input()` functions to use. Think about how you can best prevent mistakes (eg. entering free text could lead to many mistakes). 
* Another part of the user interface will allow them to choose a variable (you can limit this to only the quantitative variables) where they can explore the effects of changing that variable, holding all others constant.  
* After the user has entered all the required values, the output will be a CP profile with the the predicted value for the data that was entered, indicated by a point. You may be able to use the functions from `DALEX` and `DALEXtra` or you can do some of your own coding. 
* Use the `bslib` to theme your shiny app!  
* Publish your app to [shinyapps.io](https://www.shinyapps.io/). There are instructions for doing that on the tutorial I linked to above.   
* Write a paragraph or two describing your app on your website! Link to the app and your GitHub repository in your post. Include a link to your post here. 



## Data Ethics: Data visualization principles -- _____

Were there any principles mentioned that you hadn't heard of before? 

**I was unaware that the y axis on line graphs shouldn't include 0 and that the graoh should be much more honed in on the region of interest than zoomed out.  I actually have never done this to be honest just because I thought it was good etiquette to always start at 0...**

What graph stood out for you as "the worst"? 

**The worst has to be the bubble chart with the professor in front.  While it does have a lot of data and cool things going on, it is a mess.  With no axes and random size differences, there is so much going on the only thing you can see is relative difference.  Additionally, there is a lot of blobbing of points on top of eachother making even relative difference difficult to see.**

Did any of the graphs fool you? 

**The gun deaths in FL graph was veryyyyy confusing because of the upside down filling of it.  At first I was like wow super weird stand your ground DECREASED gun deaths but that was simply because the creator of the graph wanted you to see quite the opposite of reality.**


How does practicing good data visualization principles fit in with data ethics?

**The florida gun deaths one was a really good example of how bad data practices, no matter the intent, can actually manipulate the truth and lie to the viewer.  Such fake news would be damaging to a narrative in an election especially because of how contrary to reality it is.  If someone were to do this during election time with important stats about abortion and immigration, it would be crucial to changing minds and votes.**




